{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the conda install failed in the previous step of the quickstart please uncomment and run the following code to install the neccessary pacakges using pip\n",
    "# pip install snowflake-snowpark-python pandas notebook scikit-learn cachetools pyarrow==10.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1673289206295
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# access data from snowflake\n",
    "import pandas as pd\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.functions import *\n",
    "from snowflake.snowpark.types import *\n",
    "\n",
    "connection_parameters = {\n",
    "    \"account\": \"\",  # e.g. xy12345.us-east-2.aws\n",
    "    \"user\": \"\", \n",
    "    \"password\": \"\",\n",
    "    \"role\": \"ACCOUNTADMIN\",\n",
    "    \"warehouse\": \"HOL_WH\",\n",
    "    \"database\": \"HOL_DB\",\n",
    "    \"schema\": \"PUBLIC\"\n",
    "    }\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "\n",
    "maintenance_df = session.table('maintenance')\n",
    "humidity_df = session.table('humidity')\n",
    "hum_udi_df = session.table('city_udf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Look at Each of the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1673289209252
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "maintenance_df.to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1673289211283
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "humidity_df.to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1673289213255
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "hum_udi_df.to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1673289215264
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# join together the dataframes and prepare training dataset\n",
    "maintenance_city = maintenance_df.join(hum_udi_df, [\"UDI\"])\n",
    "maintenance_hum = maintenance_city.join(humidity_df, (maintenance_city.col(\"CITY\") == humidity_df.col(\"CITY_NAME\"))).select(col(\"TYPE\"), \n",
    "col(\"AIR_TEMPERATURE_K\"), col(\"PROCESS_TEMPERATURE\"), col(\"ROTATIONAL_SPEED_RPM\"), col(\"TORQUE_NM\"), col(\"TOOL_WEAR_MIN\"), col(\"HUMIDITY_RELATIVE_AVG\"), col(\"MACHINE_FAILURE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1673289218266
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# write training set to snowflake and materialize the data frame into a pandas data frame\n",
    "maintenance_hum.write.mode(\"overwrite\").save_as_table(\"MAINTENANCE_HUM\")\n",
    "maintenance_hum_df = session.table('MAINTENANCE_HUM').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1673289220327
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# drop redundant column\n",
    "maintenance_hum_df = maintenance_hum_df.drop(columns=[\"TYPE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Build Model that predicts machine failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1673289224282
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = maintenance_hum_df[[\"MACHINE_FAILURE\"]].to_numpy()\n",
    "X = maintenance_hum_df.drop(columns=[\"MACHINE_FAILURE\"]).to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1673289775229
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1673289777266
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# evaluate model on test\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "y_pred = logistic_model.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                   estimator_name='example estimator')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1673289778273
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# auc score\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1673289783371
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "feature_names = ['AIR_TEMPERATURE_K',\n",
    "       'PROCESS_TEMPERATURE', 'ROTATIONAL_SPEED_RPM', 'TORQUE_NM',\n",
    "       'TOOL_WEAR_MIN', 'HUMIDITY_RELATIVE_AVG']\n",
    "result = permutation_importance(\n",
    "    logistic_model, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2\n",
    ")\n",
    "\n",
    "forest_importances = pd.Series(result.importances_mean, index=feature_names)\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=result.importances_std, ax=ax)\n",
    "ax.set_title(\"Feature importances using permutation on full model\")\n",
    "ax.set_ylabel(\"Mean accuracy decrease\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "source": [
    "# Deploy Model to Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1673289787605
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# dump model to local directory\n",
    "import pickle\n",
    "pickle.dump(logistic_model, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1673290572244
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# create stage\n",
    "session.sql(\"CREATE OR REPLACE STAGE HOL_DB.PUBLIC.maint_stage\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1673290576245
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# push model to stage in snowflake\n",
    "# Model.get_model_path(model_name = 'mfr_model', version = 1, _workspace= ws)\n",
    "session.file.put('model.pkl', \"HOL_DB.PUBLIC.maint_stage\", auto_compress=False, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "session.clear_imports()\n",
    "session.clear_packages()\n",
    "\n",
    "import cachetools\n",
    "from snowflake.snowpark.types import PandasSeries, PandasDataFrame\n",
    "\n",
    "# Add trained model and Python packages from Snowflake Anaconda channel available on the server-side as UDF dependencies\n",
    "session.add_import('@maint_stage/model.pkl')\n",
    "session.add_packages('pandas','scikit-learn','cachetools')\n",
    "\n",
    "@cachetools.cached(cache={})\n",
    "def load_model(filename):\n",
    "    import joblib\n",
    "    import sys\n",
    "    import os\n",
    "\n",
    "    IMPORT_DIRECTORY_NAME = \"snowflake_import_directory\"\n",
    "    import_dir = sys._xoptions[IMPORT_DIRECTORY_NAME]\n",
    "\n",
    "    if import_dir:\n",
    "        model_file = import_dir + filename\n",
    "        with open(model_file,'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "            return model\n",
    "\n",
    "@udf(name='predict_failure',session=session,replace=True,is_permanent=True,stage_location='@maint_stage')\n",
    "def predict_failure(df: PandasDataFrame[int, int, int, int, int, int]) -> PandasSeries[float]:\n",
    "    import sklearn\n",
    "    import pandas as pd\n",
    "    df.columns = ['AIR_TEMPERATURE_K', 'PROCESS_TEMPERATURE', 'ROTATIONAL_SPEED_RPM','TORQUE_NM','TOOL_WEAR_MIN','HUMIDITY_RELATIVE_AVG']\n",
    "    model = load_model('model.pkl')\n",
    "    return model.predict_proba(df)[:,1]"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.8.16 64-bit ('3.8.16')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "5fd6d4fb3c08fc5d7d728624ab3ef85b5c959e6234d2114f093f7c9f5bf2afa2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
